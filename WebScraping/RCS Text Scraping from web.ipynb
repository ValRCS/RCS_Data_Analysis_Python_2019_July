{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AvailableDistributions',\n",
       " 'BINARY_DIST',\n",
       " 'CHECKOUT_DIST',\n",
       " 'ContextualVersionConflict',\n",
       " 'DEVELOP_DIST',\n",
       " 'DefaultProvider',\n",
       " 'DistInfoDistribution',\n",
       " 'Distribution',\n",
       " 'DistributionNotFound',\n",
       " 'EGG_DIST',\n",
       " 'EGG_NAME',\n",
       " 'EggInfoDistribution',\n",
       " 'EggMetadata',\n",
       " 'EggProvider',\n",
       " 'EmptyProvider',\n",
       " 'EntryPoint',\n",
       " 'Environment',\n",
       " 'ExtractionError',\n",
       " 'FileMetadata',\n",
       " 'IMetadataProvider',\n",
       " 'IResourceProvider',\n",
       " 'MODULE',\n",
       " 'MemoizedZipManifests',\n",
       " 'NoDists',\n",
       " 'NullProvider',\n",
       " 'PEP440Warning',\n",
       " 'PY_MAJOR',\n",
       " 'PathMetadata',\n",
       " 'Requirement',\n",
       " 'RequirementParseError',\n",
       " 'ResolutionError',\n",
       " 'ResourceManager',\n",
       " 'SOURCE_DIST',\n",
       " 'SetuptoolsLegacyVersion',\n",
       " 'SetuptoolsVersion',\n",
       " 'UnknownExtra',\n",
       " 'VersionConflict',\n",
       " 'WRITE_SUPPORT',\n",
       " 'WorkingSet',\n",
       " 'ZipManifests',\n",
       " 'ZipProvider',\n",
       " '_ReqExtras',\n",
       " '_SetuptoolsVersionMixin',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__getstate__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__setstate__',\n",
       " '__spec__',\n",
       " '_always_object',\n",
       " '_by_version_descending',\n",
       " '_bypass_ensure_directory',\n",
       " '_call_aside',\n",
       " '_declare_state',\n",
       " '_distributionImpl',\n",
       " '_distribution_finders',\n",
       " '_find_adapter',\n",
       " '_handle_ns',\n",
       " '_imp',\n",
       " '_initialize',\n",
       " '_initialize_master_working_set',\n",
       " '_is_egg_path',\n",
       " '_is_unpacked_egg',\n",
       " '_macosx_arch',\n",
       " '_macosx_vers',\n",
       " '_manager',\n",
       " '_mkstemp',\n",
       " '_namespace_handlers',\n",
       " '_namespace_packages',\n",
       " '_normalize_cached',\n",
       " '_provider_factories',\n",
       " '_rebuild_mod_path',\n",
       " '_remove_md5_fragment',\n",
       " '_set_parent_ns',\n",
       " '_sget_dict',\n",
       " '_sget_none',\n",
       " '_sget_object',\n",
       " '_sset_dict',\n",
       " '_sset_none',\n",
       " '_sset_object',\n",
       " '_state_vars',\n",
       " '_vendor',\n",
       " '_version_from_file',\n",
       " 'absolute_import',\n",
       " 'add_activation_listener',\n",
       " 'appdirs',\n",
       " 'cached_files',\n",
       " 'cleanup_resources',\n",
       " 'collections',\n",
       " 'compatible_platforms',\n",
       " 'darwinVersionString',\n",
       " 'declare_namespace',\n",
       " 'dist_factory',\n",
       " 'distributions_from_metadata',\n",
       " 'email',\n",
       " 'empty_provider',\n",
       " 'ensure_directory',\n",
       " 'errno',\n",
       " 'evaluate_marker',\n",
       " 'extern',\n",
       " 'extraction_error',\n",
       " 'extraction_path',\n",
       " 'file_ns_handler',\n",
       " 'filter',\n",
       " 'find_distributions',\n",
       " 'find_eggs_in_zip',\n",
       " 'find_nothing',\n",
       " 'find_on_path',\n",
       " 'fixup_namespace_packages',\n",
       " 'functools',\n",
       " 'get_build_platform',\n",
       " 'get_cache_path',\n",
       " 'get_default_cache',\n",
       " 'get_distribution',\n",
       " 'get_entry_info',\n",
       " 'get_entry_map',\n",
       " 'get_importer',\n",
       " 'get_platform',\n",
       " 'get_provider',\n",
       " 'get_supported_platform',\n",
       " 'importlib_machinery',\n",
       " 'inspect',\n",
       " 'invalid_marker',\n",
       " 'io',\n",
       " 'isdir',\n",
       " 'issue_warning',\n",
       " 'iter_entry_points',\n",
       " 'itertools',\n",
       " 'load_entry_point',\n",
       " 'macosVersionString',\n",
       " 'map',\n",
       " 'mkdir',\n",
       " 'non_empty_lines',\n",
       " 'normalize_path',\n",
       " 'null_ns_handler',\n",
       " 'operator',\n",
       " 'os',\n",
       " 'os_open',\n",
       " 'packaging',\n",
       " 'parse_requirements',\n",
       " 'parse_version',\n",
       " 'pkgutil',\n",
       " 'platform',\n",
       " 'plistlib',\n",
       " 'postprocess',\n",
       " 'py31compat',\n",
       " 're',\n",
       " 'register_finder',\n",
       " 'register_loader_type',\n",
       " 'register_namespace_handler',\n",
       " 'rename',\n",
       " 'require',\n",
       " 'resolve_egg_link',\n",
       " 'resource_exists',\n",
       " 'resource_filename',\n",
       " 'resource_isdir',\n",
       " 'resource_listdir',\n",
       " 'resource_stream',\n",
       " 'resource_string',\n",
       " 'run_main',\n",
       " 'run_script',\n",
       " 'safe_extra',\n",
       " 'safe_listdir',\n",
       " 'safe_name',\n",
       " 'safe_version',\n",
       " 'set_extraction_path',\n",
       " 'six',\n",
       " 'split',\n",
       " 'split_sections',\n",
       " 'stat',\n",
       " 'sys',\n",
       " 'tempfile',\n",
       " 'textwrap',\n",
       " 'time',\n",
       " 'to_filename',\n",
       " 'types',\n",
       " 'unlink',\n",
       " 'urllib',\n",
       " 'utime',\n",
       " 'warnings',\n",
       " 'working_set',\n",
       " 'yield_lines',\n",
       " 'zipfile',\n",
       " 'zipimport']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pkg_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\ProgramData\\\\Anaconda3\\\\python36.zip',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkg_resources.working_set.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkgutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pks = [mod for mod in pkgutil.iter_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pks[:15]\n",
    "len(pks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [e.name for e in pks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.index('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'scrapy' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-04d4f47e68ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'scrapy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: 'scrapy' is not in list"
     ]
    }
   ],
   "source": [
    "names.index('scrapy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201692"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/\"\n",
    "r  = requests.get(url)\n",
    "\n",
    "data = r.text\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\ProgramData\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "soup = bs(data) # the warning is because we did not specify parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 311)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txts = soup.find_all('div', attrs={\"class\":\"text-content\"})\n",
    "len(txts),len(txts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"text-content\">\n",
      "<div id=\"ban3_av\"></div><p><em>This article was originally published on October 26, 2016 and updated with new projects on 30th May, 2018.</em></p>\n",
      "<h2>Introduction</h2>\n",
      "<p>Data science projects offer you a promising way to kick-start your career in this field. Not only do you get to learn data science by applying it, you also get projects to showcase on your CV! Nowadays, recruiters evaluate a candidate’s potential by his/her work and don’t put a lot of emphasis on certifications. It wouldn’t matter if you just tell them how much you know if you have nothing to show them! That’s where most people struggle and miss out.</p>\n",
      "<p style=\"text-align: justify;\">You might have worked on several problems before, but if you can’t make it presentable &amp; easy-to-explain, how on earth would someone know what you are capable of? That’s where these projects will help you. Think of the time you’ll spend on these projects like your training sessions. The more time you spend practicing, the better you’ll become!</p>\n",
      "<p style=\"text-align: justify;\">We’ve made sure to provide you with a taste of a variety of problems from different domains. We believe everyone must learn to smartly work with huge amounts of data, hence large datasets are included. Also, we’ve made sure all the datasets are open and free to access.</p>\n",
      "<p><img alt=\"\" class=\"aligncenter wp-image-44993\" height=\"362\" sizes=\"(max-width: 543px) 100vw, 543px\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/17-DATA-SCIENCE-PROJECTS-copy.png\" srcset=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/17-DATA-SCIENCE-PROJECTS-copy.png 600w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/05/17-DATA-SCIENCE-PROJECTS-copy-300x200.png 300w\" width=\"543\"/></p>\n",
      "<h2 style=\"text-align: justify;\">Useful Information</h2>\n",
      "<p style=\"text-align: justify;\">To help you decide where to begin, we’ve divided this list into 3 levels, namely:</p>\n",
      "<ol>\n",
      "<li style=\"text-align: justify;\"><strong>Beginner Level: </strong>This level comprises of data sets which are fairly easy to work with, and don’t require complex data science techniques. You can solve them using basic regression or classification algorithms. Also, these data sets have enough open tutorials to get you going. In this list, we have also provided tutorials to help you get started.</li>\n",
      "<li style=\"text-align: justify;\"><strong>Intermediate Level:</strong> This level comprises of data sets which are more challenging in nature. It consists of mid &amp; large data sets which require some serious pattern recognition skills. Also, feature engineering will make a difference here. There is no limit on the use of ML techniques; everything under the sun can be put to use.</li>\n",
      "<li style=\"text-align: justify;\"><strong>Advanced Level:</strong> This level is best suited for people who understand advanced topics like neural networks, deep learning, recommender systems etc. High dimensional datasets are also featured here. Also, this is the time to get creative. See the creativity best data scientists bring into their work and codes.</li>\n",
      "</ol>\n",
      "<p> </p>\n",
      "<h2>Table of Contents</h2>\n",
      "<ol>\n",
      "<li>Beginner Level\n",
      "<ul>\n",
      "<li>Iris Data</li>\n",
      "<li>Loan Prediction Data</li>\n",
      "<li>Bigmart Sales Data</li>\n",
      "<li>Boston Housing Data</li>\n",
      "<li>Time Series Analysis Data</li>\n",
      "<li>Wine Quality Data</li>\n",
      "<li>Turkiye Student Evaluation Data</li>\n",
      "<li>Heights and Weights Data</li>\n",
      "</ul>\n",
      "</li>\n",
      "<li>Intermediate Level\n",
      "<ul>\n",
      "<li>Black Friday Data</li>\n",
      "<li>Human Activity Recognition Data</li>\n",
      "<li>Siam Competition Data</li>\n",
      "<li>Trip History Data</li>\n",
      "<li>Million Song Data</li>\n",
      "<li>Census Income Data</li>\n",
      "<li>Movie Lens Data</li>\n",
      "<li>Twitter Classification Data</li>\n",
      "</ul>\n",
      "</li>\n",
      "<li>Advanced Level\n",
      "<ul>\n",
      "<li>Identify your Digits</li>\n",
      "<li>Urban Sound Classification</li>\n",
      "<li>Vox Celebrity Data</li>\n",
      "<li>ImageNet Data</li>\n",
      "<li>Chicago Crime Data</li>\n",
      "<li>Age Detection of Indian Actors Data</li>\n",
      "<li>Recommendation Engine Data</li>\n",
      "<li>VisualQA Data</li>\n",
      "</ul>\n",
      "</li>\n",
      "</ol>\n",
      "<p> </p>\n",
      "<h2>Beginner Level</h2>\n",
      "<h3>1. Iris Data Set</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"iris_dataset_scatterplot-svg\" class=\"alignright wp-image-28567 \" height=\"105\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/Iris_dataset_scatterplot.svg_-150x150.png\" width=\"132\"/>This is probably the most versatile, easy and resourceful dataset in pattern recognition literature. Nothing could be simpler than the Iris dataset to learn classification techniques. If you are totally new to data science, this is your start line. The data has only 150 rows &amp; 4 columns.</p>\n",
      "<p><strong>Problem:</strong> Predict the class of the flower based on available attributes.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://archive.ics.uci.edu/ml/datasets/Iris\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"http://www.slideshare.net/thoi_gian/iris-data-analysis-with-r\" rel=\"nofollow noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>2. Loan Prediction Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"ss\" class=\"alignright wp-image-28588 \" height=\"134\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/ss-150x150.jpg\" width=\"136\"/>Among all industries, the insurance domain has one of the largest uses of analytics &amp; data science methods. This dataset provides you a taste of working on data sets from insurance companies – what challenges are faced there, what strategies are used, which variables influence the outcome, etc. This is a classification problem. The data has 615 rows and 13 columns.</p>\n",
      "<p><strong>Problem:</strong> Predict if a loan will get approved or not.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/\" rel=\"nofollow noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>3. Bigmart Sales Data Set</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"shopping-cart-1269174_960_720\" class=\"alignright wp-image-28570 \" height=\"99\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/shopping-cart-1269174_960_720-150x150.jpg\" width=\"113\"/>Retail is another industry which extensively uses analytics to optimize business processes. Tasks like product placement, inventory management, customized offers, product bundling, etc. are being smartly handled using data science techniques. As the name suggests, this data comprises of transaction records of a sales store. This is a regression problem. The data has 8523 rows of 12 variables.</p>\n",
      "<p><strong>Problem:</strong> Predict the sales of a store.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www.analyticsvidhya.com/blog/2016/02/bigmart-sales-solution-top-20/\" rel=\"nofollow noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>4. Boston Housing Data Set</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"14938-illustration-of-a-yellow-house-pv\" class=\"alignright wp-image-28571 \" height=\"62\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/14938-illustration-of-a-yellow-house-pv-300x169.png\" width=\"147\"/>This is another popular dataset used in pattern recognition literature. The data set comes from the real estate industry in Boston (US). This is a regression problem. The data has 506 rows and 14 columns. Thus, it’s a fairly small data set where you can attempt any technique without worrying about your laptop’s memory being overused.</p>\n",
      "<p><strong>Problem:</strong> Predict the median value of owner occupied homes.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\" rel=\"noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www.analyticsvidhya.com/blog/2015/11/started-machine-learning-ms-excel-xl-miner/\" rel=\"nofollow noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>5. Time Series Analysis Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"\" class=\"wp-image-43756 alignright\" height=\"98\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/time-series.gif\" width=\"154\"/></p>\n",
      "<p>Time Series is one of the most commonly used techniques in data science. It has wide ranging applications – weather forecasting, predicting sales, analyzing year on year trends, etc. This dataset is specific to time series and the challenge here is to forecast traffic on a mode of transportation. The data has ** rows and ** columns.</p>\n",
      "<p><strong>Problem:</strong> Predict the traffic on a new mode of transport.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-time-series-2/\" rel=\"noopener\" target=\"_blank\">Get Data</a>  | <strong>Tutorial:</strong> <a href=\"https://trainings.analyticsvidhya.com/courses/course-v1:AnalyticsVidhya+TS_101+TS_term1/about\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>6. Wine Quality Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"\" class=\"wp-image-43749 alignright\" height=\"110\" sizes=\"(max-width: 147px) 100vw, 147px\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/WINE.jpg\" srcset=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/WINE.jpg 540w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/WINE-300x225.jpg 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/WINE-83x63.jpg 83w\" width=\"147\"/>This is one of the most popular datasets along data science beginners. It is divided into 2 datasets. You can perform both regression and classification tasks on this data. It will test your understanding in different fields – outlier detection, feature selection, and unbalanced data. There are 4898 rows and 12 columns in this dataset.</p>\n",
      "<p><strong>Problem:</strong> Predict the quality of the wine.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://archive.ics.uci.edu/ml/datasets/Wine+Quality\" rel=\"noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://web.stanford.edu/~ilker/doc/wine_Stats315A.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>7. Turkiye Student Evaluation Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"\" class=\"wp-image-43760 alignright\" height=\"109\" sizes=\"(max-width: 152px) 100vw, 152px\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/140423_EDU_StudentEvaluation.jpg.CROP_.promo-mediumlarge.jpg\" srcset=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/140423_EDU_StudentEvaluation.jpg.CROP_.promo-mediumlarge.jpg 590w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/140423_EDU_StudentEvaluation.jpg.CROP_.promo-mediumlarge-300x214.jpg 300w\" width=\"152\"/></p>\n",
      "<p>This dataset is based on an evaluation form filled out by students for different courses. It has different attributes including attendance, difficulty, score for each evaluation question, among others. This is an unsupervised learning problem. The dataset has 5820 rows and 33 columns.</p>\n",
      "<p><strong>Problem: </strong>Use classification and clustering techniques to deal with the data.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://archive.ics.uci.edu/ml/datasets/Wine+Qualityhttps://archive.ics.uci.edu/ml/datasets/Turkiye+Student+Evaluation\" rel=\"noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://sanghosuh.github.io/research/LA_EdMining_SanghoSuh.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>8. Heights and Weights Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"\" class=\"wp-image-43763 alignright\" height=\"123\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/46612356_thumbnail-300x257.jpg\" width=\"144\"/></p>\n",
      "<p>This is a fairly straightforward problem and is ideal for people starting off with data science. It is a regression problem.  The dataset has 25,000 rows and 3 columns (index, height and weight).</p>\n",
      "<p><strong>Problem:</strong> Predict the height or weight of a person.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_020108_HeightsWeights\" rel=\"noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www3.nd.edu/~steve/computing_with_data/2_Motivation/motivate_ht_wt.html\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h2>Intermediate Level</h2>\n",
      "<h3>1. Black Friday Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"black-friday\" class=\"wp-image-28573 alignright\" height=\"87\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/Black-Friday.jpg\" width=\"146\"/>This dataset comprises of sales transactions captured at a retail store. It’s a classic dataset to explore and expand your feature engineering skills and day to day understanding from multiple shopping experiences. This is a regression problem. The dataset has 550,069 rows and 12 columns.</p>\n",
      "<p><strong>Problem:</strong> Predict purchase amount.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://datahack.analyticsvidhya.com/contest/black-friday/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://discuss.analyticsvidhya.com/t/black-friday-data-hack-reveal-your-approach/5986\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>2. Human Activity Recognition Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"as\" class=\" wp-image-28589 alignright\" height=\"107\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/as.jpg\" width=\"157\"/>This data set is collected from recordings of 30 human subjects captured via smartphones enabled with embedded inertial sensors. Many machine learning courses use this data for teaching purposes. It’s your turn now. This is a multi-classification problem. The data set has 10,299 rows and 561 columns.</p>\n",
      "<p><strong>Problem:</strong> Predict the activity category of a human.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://rstudio-pubs-static.s3.amazonaws.com/291850_859937539fb14c37b0a311db344a6016.html\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>3. Text Mining Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"De l'éloquence judiciaire À Athenes\" class=\"alignright wp-image-28575 \" height=\"93\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/text-mining-150x150.jpg\" width=\"119\"/>This dataset is originally from the Siam Text Mining Competition held in 2007. The data comprises of aviation safety reports describing problem(s) which occurred in certain flights. It is a multi-classification and high dimensional problem. It has 21,519 rows and 30,438 columns.</p>\n",
      "<p><strong>Problem:</strong> Classify the documents according to their labels.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html#siam-competition2007\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://wtlab.um.ac.ir/images/e-library/text_mining/Survey%20of%20Text%20Mining%202%20.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>4. Trip History Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"trip-history-data\" class=\"alignright wp-image-28576 \" height=\"110\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/trip-history-data-150x150.jpg\" width=\"114\"/>This dataset comes from a bike sharing service in the United States. This dataset requires you to exercise your pro data munging skills. The data is provided quarter-wise from 2010 (Q4) onwards. Each file has 7 columns. It is a classification problem.</p>\n",
      "<p><strong>Problem:</strong> Predict the class of user.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://www.capitalbikeshare.com/trip-history-data\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www.analyticsvidhya.com/blog/2015/06/solution-kaggle-competition-bike-sharing-demand/\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>5. Million Song Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"million-song\" class=\"alignright wp-image-28577 \" height=\"87\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/million-song-300x169.jpg\" width=\"150\"/>Did you know data science can be used in the entertainment industry also? Do it yourself now. This data set puts forward a regression task. It consists of 5,15,345 observations and 90 variables. However, this is just a tiny subset of the <a href=\"http://labrosa.ee.columbia.edu/millionsong/pages/getting-dataset\" rel=\"nofollow noopener\" target=\"_blank\">original database</a> of data about a million songs.</p>\n",
      "<p><strong>Problem:</strong> Predict release year of the song.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://archive.ics.uci.edu/ml/datasets/YearPredictionMSD\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"http://www-personal.umich.edu/~yjli/content/projectreport.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>6. Census Income Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"us-census\" class=\"alignright wp-image-28578 \" height=\"81\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/US-Census-300x228.png\" width=\"160\"/>It’s an imbalanced classification and a classic machine learning problem. You know, machine learning is being extensively used to solve imbalanced problems such as cancer detection, fraud detection etc. It’s time to get your hands dirty. The data set has 48,842 rows and 14 columns. For guidance, you can check this <a href=\"https://www.analyticsvidhya.com/blog/2016/09/this-machine-learning-project-on-imbalanced-data-can-add-value-to-your-resume/\" rel=\"nofollow noopener\" target=\"_blank\">imbalanced data project</a>.</p>\n",
      "<p><strong>Problem:</strong> Predict the income class of US population.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://cseweb.ucsd.edu/~jmcauley/cse190/reports/sp15/048.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>7. Movie Lens Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"movie-lens-data\" class=\"alignright wp-image-28579 \" height=\"79\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/movie-lens-data-300x201.jpg\" width=\"159\"/>Have you built a recommendation system yet? Here’s your chance! This dataset is one of the most popular &amp; quoted datasets in the data science industry. It is available in <a href=\"http://grouplens.org/datasets/movielens/\" rel=\"nofollow noopener\" target=\"_blank\">various dimensions</a>. Here I’ve used a fairly small size. It has 1 million ratings from 6,000 users on 4,000 movies.</p>\n",
      "<p><strong>Problem:</strong> Recommend new movies to users.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://grouplens.org/datasets/movielens/1m/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www.analyticsvidhya.com/blog/2016/06/quick-guide-build-recommendation-engine-python/\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>8. Twitter Classification Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"Mining Twitter Data\" class=\"wp-image-9696 alignright\" height=\"116\" sizes=\"(max-width: 140px) 100vw, 140px\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2014/11/Mining_Twitter_Data.jpg\" srcset=\"https://www.analyticsvidhya.com/wp-content/uploads/2014/11/Mining_Twitter_Data.jpg 450w, https://www.analyticsvidhya.com/wp-content/uploads/2014/11/Mining_Twitter_Data-300x248.jpg 300w\" width=\"140\"/>Working with Twitter data has become an integral part of sentiment analysis problems. If you want to carve a niche for yourself in this area, you will have fun working on the challenge this dataset poses. The dataset is 3MB in size and has 31,962 tweets.</p>\n",
      "<p><strong>Problem: </strong>Identify the tweets which are hate tweets and which are not.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/\" rel=\"noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://github.com/abdulfatir/twitter-sentiment-analysis\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h2>Advanced Level</h2>\n",
      "<h3>1. Identify your Digits Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"identify-the-digits\" class=\"alignright wp-image-28584 \" height=\"99\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/identify-the-digits-1-150x150.jpg\" width=\"117\"/>This dataset allows you to study, analyze and recognize elements in the images. That’s exactly how your camera detects your face, using image recognition! It’s your turn to build and test that technique. It’s a digit recognition problem. This data set has 7,000 images of 28 X 28 size, totalling 31MB.</p>\n",
      "<p><strong>Problem:</strong> Identify digits from an image.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>2. Urban Sound Classification</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"\" class=\"wp-image-43753 alignright\" height=\"92\" sizes=\"(max-width: 200px) 100vw, 200px\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/Practice_Problem_1920_480-thumbnail-1200x12001.png\" srcset=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/Practice_Problem_1920_480-thumbnail-1200x12001.png 651w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/Practice_Problem_1920_480-thumbnail-1200x12001-300x138.png 300w\" width=\"200\"/></p>\n",
      "<p>When you start your machine learning journey, you go with simple machine learning problems like titanic survival prediction. But you still don’t have enough practice when it comes to real life problems. Hence, this practice problem is meant to introduce you to audio processing in the usual classification scenario. This dataset consists of 8,732 sound excerpts of urban sounds from 10 classes.</p>\n",
      "<p><strong>Problem:</strong> Classify the type of sound from the audio.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/\" rel=\"noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www.analyticsvidhya.com/blog/2017/08/audio-voice-processing-deep-learning/\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>3. Vox Celebrity Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"\" class=\"wp-image-43759 alignright\" height=\"115\" sizes=\"(max-width: 225px) 100vw, 225px\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/vox.png\" srcset=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/vox.png 514w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/vox-300x152.png 300w\" width=\"225\"/></p>\n",
      "<p>Audio processing is rapidly becoming an important field in deep learning hence here’s another challenging problem. This dataset is for large-scale speaker identification and contains words spoken by celebrities, extracted from YouTube videos. It’s an intriguing use case for isolating and identifying speech recognition. The data contains 100,000 utterances spoken by 1,251 celebrities.</p>\n",
      "<p><strong>Problem:</strong> Figure out which celebrity the voice belongs to.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://www.robots.ox.ac.uk/~vgg/data/voxceleb/\" rel=\"noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www.robots.ox.ac.uk/~vgg/publications/2017/Nagrani17/nagrani17.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>4. ImageNet Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"la\" class=\"alignright wp-image-28590 \" height=\"84\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/la-300x174.png\" width=\"191\"/>ImageNet offers variety of problems which encompasses object detection, localization, classification and screen parsing. All the images are freely available. You can search for any type of image and build your project around it. As of now, this image engine has more than 15 million images of multiple shapes sizing up to 140GB.</p>\n",
      "<p><strong>Problem:</strong> Problem to solve is subjected to the image type you download.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://image-net.org/download-imageurls\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"http://image-net.org/download-imageurls\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>5. Chicago Crime Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"chicago-crime\" class=\"alignright wp-image-28583 \" height=\"133\" src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/10/chicago-crime-300x225.jpg\" width=\"175\"/>The ability to handle large datasets is expected of every data scientist these days. Companies no longer prefer to work on samples when they the computational power to work on the full dataset. This dataset provides you a much needed hands-on experience of handling large data sets on your local machines. The problem is easy, but data management is the key! This dataset has 6M observations. It’s a multi-classification problem.</p>\n",
      "<p><strong>Problem:</strong> Predict the type of crime.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"http://nathanwayneholt.com/mathematicalmodeling/ChicagoCrimesReport.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>6. Age Detection of Indian Actors Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"\" class=\"wp-image-43750 alignright\" height=\"115\" sizes=\"(max-width: 177px) 100vw, 177px\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/age-detection.png\" srcset=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/age-detection.png 463w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/age-detection-300x194.png 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/age-detection-258x169.png 258w\" width=\"177\"/></p>\n",
      "<p>This is a fascinating challenge for any deep learning enthusiast. The dataset contains thousands of images of Indian actors and your task is to identify their age. All the images are manually selected and cropped from the video frames resulting in a high degree of variability interms of scale, pose, expression, illumination, age, resolution, occlusion, and makeup. There are 19,906 images in the training set and 6,636 in the test set.</p>\n",
      "<p><strong>Problem:</strong> Predict the age of the actors.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://image-net.org/download-imageurls\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://www.analyticsvidhya.com/blog/2017/06/hands-on-with-deep-learning-solution-for-age-detection-practice-problem/\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h3>7. Recommendation Engine Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"\" class=\"wp-image-43757 alignright\" height=\"113\" sizes=\"(max-width: 169px) 100vw, 169px\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/recommendation-system.png\" srcset=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/recommendation-system.png 619w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/recommendation-system-300x200.png 300w\" width=\"169\"/></p>\n",
      "<p>This is an advanced recommendation system challenge. In this practice problem, you are given the data of programmers and questions that they have previously solved, along with the time that they took to solve that particular question. As a data scientist, the model you build will help online judges to decide the next level of questions to recommend to a user.</p>\n",
      "<p><strong>Problem:</strong> Predict the time taken to solve a problem given the current status of the user.</p>\n",
      "<p><strong>Start:</strong> <a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-recommendation-engine/\" rel=\"noopener\" target=\"_blank\">Get Data</a></p>\n",
      "<p> </p>\n",
      "<h3>8. VisualQA Dataset</h3>\n",
      "<p style=\"text-align: justify;\"><img alt=\"\" class=\"wp-image-43754 alignright\" height=\"130\" sizes=\"(max-width: 231px) 100vw, 231px\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/VQA-768x432.jpg\" srcset=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/VQA-768x432.jpg 768w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/VQA-768x432-300x169.jpg 300w, https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/04/VQA-768x432-257x144.jpg 257w\" width=\"231\"/></p>\n",
      "<p>VisualQA is a dataset containing open-ended questions about images. These questions require an understanding of computer vision and language. There is an automatic evaluation metric for this problem. The dataset has 265,016 images, 3 questions per image and 10 ground truth answers per question.</p>\n",
      "<p><strong>Problem:</strong> Use deep learning technique to answer open-ended questions about images.</p>\n",
      "<p><strong>Start:</strong> <a href=\"http://www.visualqa.org\" rel=\"noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"https://arxiv.org/abs/1708.02711\" rel=\"noopener\" target=\"_blank\">Get Here</a></p>\n",
      "<p> </p>\n",
      "<h2>End Notes</h2>\n",
      "<p style=\"text-align: justify;\">Out of the 24 datasets listed above, you should start by finding the one that matches your skillset. Say, if you are a beginner in machine learning, avoid taking up advanced level data sets from the get go. Don’t bite more than you can chew and don’t feel overwhelmed with how much you still have to do. Instead, focus on making step-wise progress.</p>\n",
      "<p style=\"text-align: justify;\">Once you complete 2 – 3 projects, showcase them on your resume and your GitHub profile (very important!). Lots of recruiters these days hire candidates by checking their GitHub profiles. Your motive shouldn’t be to do all the projects, but to pick out selected ones based on the problem to be solved, domain and the dataset size. If you want to look at complete project solution, take a look at <a href=\"https://www.analyticsvidhya.com/blog/2016/09/this-machine-learning-project-on-imbalanced-data-can-add-value-to-your-resume/\" rel=\"noopener\" target=\"_blank\">this article</a>.</p>\n",
      "<p style=\"text-align: justify;\">Did you find this article useful? Have you already built any projects on these datasets? Do share your experience, learnings and suggestions in the comments section below.</p>\n",
      "<p> </p>\n",
      "<h3 style=\"text-align: justify;\">Participate in our <a href=\"http://datahack.analyticsvidhya.com/contest/all\" rel=\"nofollow noopener\" target=\"_blank\">Hackathons</a> and compete with the best Data Scientists from all over the world!</h3>\n",
      "<p> </p>\n",
      "You can also read this article on Analytics Vidhya's Android APP <a href=\"//play.google.com/store/apps/details?id=com.analyticsvidhya.android&amp;utm_source=blog_article&amp;utm_campaign=blog&amp;pcampaignid=MKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1\" onclick=\"ga('send', {'hitType': 'event', 'eventCategory': 'app-blog', 'eventAction': 'clicked'});\"><img alt=\"Get it on Google Play\" src=\"//play.google.com/intl/en_us/badges/images/generic/en_badge_web_generic.png\" style=\"height:65px\"/></a><script async=\"\" src=\"//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\"></script>\n",
      "<ins class=\"adsbygoogle\" data-ad-client=\"ca-pub-5229672700622157\" data-ad-slot=\"7938033629\" style=\"display:inline-block;width:728px;height:90px\"></ins>\n",
      "<script>\n",
      "(adsbygoogle = window.adsbygoogle || []).push({});\n",
      "</script>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(txts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = txts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = txt.findAll(['p','h2','h3'])\n",
    "len(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p><em>This article was originally published on October 26, 2016 and updated with new projects on 30th May, 2018.</em></p>,\n",
       " <h2>Introduction</h2>,\n",
       " <p>Data science projects offer you a promising way to kick-start your career in this field. Not only do you get to learn data science by applying it, you also get projects to showcase on your CV! Nowadays, recruiters evaluate a candidate’s potential by his/her work and don’t put a lot of emphasis on certifications. It wouldn’t matter if you just tell them how much you know if you have nothing to show them! That’s where most people struggle and miss out.</p>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=ps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p><em>This article was originally published on October 26, 2016 and updated with new projects on 30th May, 2018.</em></p>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p><strong>Start:</strong> <a href=\"https://archive.ics.uci.edu/ml/datasets/Iris\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a> | <strong>Tutorial:</strong> <a href=\"http://www.slideshare.net/thoi_gian/iris-data-analysis-with-r\" rel=\"nofollow noopener\" target=\"_blank\">Get Here</a></p>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('paragraphs.txt', mode='w') as f:\n",
    "    f.write(f'OG URL:{url}\\n\\n')\n",
    "    for p in ps:\n",
    "        pad=\"\"\n",
    "        if p.name == 'h3':\n",
    "            pad='### '\n",
    "        elif p.name == 'h2':\n",
    "            pad='## '\n",
    "        if len(p.findAll('a')):\n",
    "            f.write(f\"{pad}{p.text}\\n\\n\") ##TODO need to figure out how to only get parent text\n",
    "            for e in p.findAll('a'):\n",
    "                f.write(f\"[{e.text}]({e['href']})\\n\\n\") \n",
    "        else:\n",
    "            f.write(f\"{pad}{p.text}\\n\\n\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kids = list(txt.findChildren(recursive=True))\n",
    "len(kids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('projects.txt', mode='w') as f:\n",
    "    for e in kids:\n",
    "        f.write(e.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('content.txt', mode='w') as f:\n",
    "    for e in kids:\n",
    "        f.write(str(e.contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(kids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "kds = [el for el in kids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://archive.ics.uci.edu/ml/datasets/Iris\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"http://www.slideshare.net/thoi_gian/iris-data-analysis-with-r\" rel=\"nofollow noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/\" rel=\"nofollow noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2016/02/bigmart-sales-solution-top-20/\" rel=\"nofollow noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2015/11/started-machine-learning-ms-excel-xl-miner/\" rel=\"nofollow noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-time-series-2/\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://trainings.analyticsvidhya.com/courses/course-v1:AnalyticsVidhya+TS_101+TS_term1/about\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://archive.ics.uci.edu/ml/datasets/Wine+Quality\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://web.stanford.edu/~ilker/doc/wine_Stats315A.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://archive.ics.uci.edu/ml/datasets/Wine+Qualityhttps://archive.ics.uci.edu/ml/datasets/Turkiye+Student+Evaluation\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://sanghosuh.github.io/research/LA_EdMining_SanghoSuh.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_020108_HeightsWeights\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www3.nd.edu/~steve/computing_with_data/2_Motivation/motivate_ht_wt.html\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://datahack.analyticsvidhya.com/contest/black-friday/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://discuss.analyticsvidhya.com/t/black-friday-data-hack-reveal-your-approach/5986\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://rstudio-pubs-static.s3.amazonaws.com/291850_859937539fb14c37b0a311db344a6016.html\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html#siam-competition2007\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://wtlab.um.ac.ir/images/e-library/text_mining/Survey%20of%20Text%20Mining%202%20.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://www.capitalbikeshare.com/trip-history-data\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2015/06/solution-kaggle-competition-bike-sharing-demand/\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"http://labrosa.ee.columbia.edu/millionsong/pages/getting-dataset\" rel=\"nofollow noopener\" target=\"_blank\">original database</a>\n",
      "<a href=\"http://archive.ics.uci.edu/ml/datasets/YearPredictionMSD\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"http://www-personal.umich.edu/~yjli/content/projectreport.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2016/09/this-machine-learning-project-on-imbalanced-data-can-add-value-to-your-resume/\" rel=\"nofollow noopener\" target=\"_blank\">imbalanced data project</a>\n",
      "<a href=\"http://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://cseweb.ucsd.edu/~jmcauley/cse190/reports/sp15/048.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"http://grouplens.org/datasets/movielens/\" rel=\"nofollow noopener\" target=\"_blank\">various dimensions</a>\n",
      "<a href=\"http://grouplens.org/datasets/movielens/1m/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2016/06/quick-guide-build-recommendation-engine-python/\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://github.com/abdulfatir/twitter-sentiment-analysis\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2017/08/audio-voice-processing-deep-learning/\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"http://www.robots.ox.ac.uk/~vgg/data/voxceleb/\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www.robots.ox.ac.uk/~vgg/publications/2017/Nagrani17/nagrani17.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"http://image-net.org/download-imageurls\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"http://image-net.org/download-imageurls\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"http://nathanwayneholt.com/mathematicalmodeling/ChicagoCrimesReport.pdf\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"http://image-net.org/download-imageurls\" rel=\"nofollow noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2017/06/hands-on-with-deep-learning-solution-for-age-detection-practice-problem/\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://datahack.analyticsvidhya.com/contest/practice-problem-recommendation-engine/\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"http://www.visualqa.org\" rel=\"noopener\" target=\"_blank\">Get Data</a>\n",
      "<a href=\"https://arxiv.org/abs/1708.02711\" rel=\"noopener\" target=\"_blank\">Get Here</a>\n",
      "<a href=\"https://www.analyticsvidhya.com/blog/2016/09/this-machine-learning-project-on-imbalanced-data-can-add-value-to-your-resume/\" rel=\"noopener\" target=\"_blank\">this article</a>\n",
      "<a href=\"http://datahack.analyticsvidhya.com/contest/all\" rel=\"nofollow noopener\" target=\"_blank\">Hackathons</a>\n",
      "<a href=\"//play.google.com/store/apps/details?id=com.analyticsvidhya.android&amp;utm_source=blog_article&amp;utm_campaign=blog&amp;pcampaignid=MKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1\" onclick=\"ga('send', {'hitType': 'event', 'eventCategory': 'app-blog', 'eventAction': 'clicked'});\"><img alt=\"Get it on Google Play\" src=\"//play.google.com/intl/en_us/badges/images/generic/en_badge_web_generic.png\" style=\"height:65px\"/></a>\n"
     ]
    }
   ],
   "source": [
    "for e in kds:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
